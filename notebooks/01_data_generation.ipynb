{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f01216-fc3d-46dd-b8fe-2cd19daadfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè≠ Generating synthetic data with optimized approach...\n",
      "‚úÖ Initialized: 5 stores, 40 products\n",
      "\n",
      "üìä Generating sales transactions...\n",
      "üöÄ Generating sales data with optimized approach...\n",
      "üìä Processing 43840 combinations...\n",
      "üî¢ Calculating demand patterns...\n",
      "üîß Adding realistic data quality issues...\n",
      "‚úÖ Generated 40572 sales records\n",
      "\n",
      "üì¶ Generating inventory snapshots...\n",
      "üì¶ Generating inventory data...\n",
      "‚úÖ Generated 8342 inventory records\n",
      "\n",
      "üå°Ô∏è Generating external factors...\n",
      "üå°Ô∏è Generating external factors...\n",
      "‚úÖ Generated 3655 external factor records\n",
      "\n",
      "‚úÖ Data generation complete!\n",
      "üìà Sales records: 40,572\n",
      "üì¶ Inventory snapshots: 8,342\n",
      "üå°Ô∏è External factor records: 3,655\n",
      "üö® Total missing values: 7028\n",
      "\n",
      "üîç Sample Sales Data:\n",
      "  transaction_id store_id product_id       date  sales_quantity  unit_price  \\\n",
      "0       TXN32000    ST001       P002 2022-01-01              14      324.08   \n",
      "1       TXN98820    ST001       P003 2022-01-01               6       59.41   \n",
      "2       TXN53073    ST999       P004 2022-01-01             624      133.85   \n",
      "3       TXN56874    ST001       P008 2022-01-01              10       14.08   \n",
      "4       TXN43426    ST001       P010 2022-01-01               6      271.35   \n",
      "\n",
      "   total_revenue  \n",
      "0        4537.12  \n",
      "1         356.46  \n",
      "2        1070.80  \n",
      "3         140.80  \n",
      "4        1628.10  \n",
      "\n",
      "üîç Data Quality Issues:\n",
      "Missing values: 5927\n",
      "Negative quantities: 223\n",
      "Duplicate transaction IDs: 8255\n",
      "Wrong store IDs: 391\n"
     ]
    }
   ],
   "source": [
    "#Synthetic Data Generator\n",
    "# This version generates the same realistic data but much faster\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "import random\n",
    "import json\n",
    "\n",
    "fake = Faker()\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "class OptimizedInventoryDataGenerator:\n",
    "    def __init__(self):\n",
    "        self.stores = self._create_stores()\n",
    "        self.products = self._create_products()\n",
    "        self.holidays = self._create_holidays()\n",
    "        print(f\"‚úÖ Initialized: {len(self.stores)} stores, {len(self.products)} products\")\n",
    "\n",
    "    def _create_stores(self):\n",
    "        \"\"\"Create 5 different store profiles\"\"\"\n",
    "        stores = [\n",
    "            {'store_id': 'ST001', 'name': 'Downtown Grocery', 'type': 'grocery', 'size': 'medium', 'city': 'Boston'},\n",
    "            {'store_id': 'ST002', 'name': 'MedCare Pharmacy', 'type': 'pharmacy', 'size': 'small', 'city': 'Austin'},\n",
    "            {'store_id': 'ST003', 'name': 'TechMart Electronics', 'type': 'electronics', 'size': 'large', 'city': 'Seattle'},\n",
    "            {'store_id': 'ST004', 'name': 'Corner Market', 'type': 'grocery', 'size': 'small', 'city': 'Denver'},\n",
    "            {'store_id': 'ST005', 'name': 'Campus Pharmacy', 'type': 'pharmacy', 'size': 'medium', 'city': 'Chicago'}\n",
    "        ]\n",
    "        return pd.DataFrame(stores)\n",
    "\n",
    "    def _create_products(self):\n",
    "        \"\"\"Create 50 products across different categories\"\"\"\n",
    "        categories = {\n",
    "            'grocery': ['Milk', 'Bread', 'Eggs', 'Apples', 'Bananas', 'Chicken', 'Rice', 'Pasta',\n",
    "                       'Yogurt', 'Cheese', 'Tomatoes', 'Onions', 'Potatoes', 'Cereal', 'Orange Juice'],\n",
    "            'pharmacy': ['Aspirin', 'Vitamins', 'Band-aids', 'Cough Syrup', 'Antacid', 'Thermometer',\n",
    "                        'Hand Sanitizer', 'Face Masks', 'Eye Drops', 'Pain Relief', 'Allergy Pills'],\n",
    "            'electronics': ['Phone Charger', 'Bluetooth Speaker', 'Headphones', 'USB Cable', 'Power Bank',\n",
    "                           'Phone Case', 'Screen Protector', 'Gaming Controller', 'Wireless Mouse', 'Keyboard',\n",
    "                           'Webcam', 'HDMI Cable', 'Memory Card', 'Tablet Stand']\n",
    "        }\n",
    "\n",
    "        products = []\n",
    "        pid = 1\n",
    "        for category, items in categories.items():\n",
    "            for item in items:\n",
    "                products.append({\n",
    "                    'product_id': f'P{pid:03d}',\n",
    "                    'name': item,\n",
    "                    'category': category,\n",
    "                    'unit_cost': round(np.random.uniform(5, 200), 2),\n",
    "                    'unit_price': 0,  # Will calculate with margin\n",
    "                    'shelf_life_days': np.random.choice([7, 30, 365, 1095]),\n",
    "                    'seasonality_factor': round(np.random.uniform(0.5, 2.0), 2)\n",
    "                })\n",
    "                pid += 1\n",
    "\n",
    "        df = pd.DataFrame(products)\n",
    "        df['unit_price'] = round(df['unit_cost'] * np.random.uniform(1.3, 2.5, len(df)), 2)\n",
    "        return df\n",
    "\n",
    "    def _create_holidays(self):\n",
    "        \"\"\"Create holiday calendar\"\"\"\n",
    "        holidays = []\n",
    "        years = [2022, 2023, 2024]\n",
    "        for year in years:\n",
    "            holiday_dates = [\n",
    "                f'{year}-01-01',  # New Year\n",
    "                f'{year}-07-04',  # July 4th\n",
    "                f'{year}-11-24' if year == 2022 else f'{year}-11-23' if year == 2023 else f'{year}-11-28',  # Thanksgiving\n",
    "                f'{year}-12-25',  # Christmas\n",
    "                f'{year}-03-17',  # St Patrick's Day\n",
    "                f'{year}-10-31',  # Halloween\n",
    "            ]\n",
    "            for date in holiday_dates:\n",
    "                holidays.append({'date': date, 'is_holiday': True})\n",
    "        return pd.DataFrame(holidays)\n",
    "\n",
    "    def generate_sales_data_optimized(self, start_date='2022-01-01', end_date='2024-01-01', sample_rate=0.3):\n",
    "        \"\"\"Generate messy sales transaction data - OPTIMIZED version\"\"\"\n",
    "        print(\"üöÄ Generating sales data with optimized approach...\")\n",
    "        \n",
    "        # Create date range\n",
    "        date_range = pd.date_range(start_date, end_date, freq='D')\n",
    "        \n",
    "        # Create all possible combinations but sample them\n",
    "        all_combinations = []\n",
    "        for date in date_range:\n",
    "            for store_id in self.stores['store_id']:\n",
    "                for product_id in self.products['product_id']:\n",
    "                    # Sample combinations to reduce data size\n",
    "                    if random.random() < sample_rate:\n",
    "                        all_combinations.append({\n",
    "                            'date': date,\n",
    "                            'store_id': store_id,\n",
    "                            'product_id': product_id\n",
    "                        })\n",
    "        \n",
    "        print(f\"üìä Processing {len(all_combinations)} combinations...\")\n",
    "        \n",
    "        # Convert to DataFrame for vectorized operations\n",
    "        base_df = pd.DataFrame(all_combinations)\n",
    "        \n",
    "        # Merge with store and product info\n",
    "        base_df = base_df.merge(self.stores[['store_id', 'size', 'type', 'city']], on='store_id')\n",
    "        base_df = base_df.merge(self.products[['product_id', 'category', 'unit_price']], on='product_id')\n",
    "        \n",
    "        # Vectorized demand calculation\n",
    "        print(\"üî¢ Calculating demand patterns...\")\n",
    "        base_df['base_demand'] = self._calculate_vectorized_demand(base_df)\n",
    "        \n",
    "        # Generate sales quantities\n",
    "        base_df['sales_quantity'] = np.random.poisson(base_df['base_demand'])\n",
    "        \n",
    "        # Remove zero sales\n",
    "        sales_df = base_df[base_df['sales_quantity'] > 0].copy()\n",
    "        \n",
    "        # Add transaction details\n",
    "        sales_df['transaction_id'] = ['TXN' + str(fake.random_int(10000, 99999)) for _ in range(len(sales_df))]\n",
    "        sales_df['total_revenue'] = sales_df['sales_quantity'] * sales_df['unit_price']\n",
    "        \n",
    "        # Add data quality issues\n",
    "        print(\"üîß Adding realistic data quality issues...\")\n",
    "        sales_df = self._add_vectorized_data_issues(sales_df)\n",
    "        \n",
    "        # Select final columns\n",
    "        final_columns = ['transaction_id', 'store_id', 'product_id', 'date', \n",
    "                        'sales_quantity', 'unit_price', 'total_revenue']\n",
    "        sales_df = sales_df[final_columns]\n",
    "        \n",
    "        print(f\"‚úÖ Generated {len(sales_df)} sales records\")\n",
    "        return sales_df\n",
    "\n",
    "    def _calculate_vectorized_demand(self, df):\n",
    "        \"\"\"Vectorized demand calculation\"\"\"\n",
    "        # Base demand by category\n",
    "        category_base = {'grocery': 8, 'pharmacy': 3, 'electronics': 2}\n",
    "        base_demand = df['category'].map(category_base)\n",
    "        \n",
    "        # Store size multiplier\n",
    "        size_multiplier = {'small': 0.7, 'medium': 1.0, 'large': 1.5}\n",
    "        base_demand *= df['size'].map(size_multiplier)\n",
    "        \n",
    "        # Day of week impact\n",
    "        weekday_multipliers = [0.8, 0.9, 0.9, 0.9, 1.1, 1.4, 1.3]  # Mon-Sun\n",
    "        base_demand *= df['date'].dt.weekday.map(lambda x: weekday_multipliers[x])\n",
    "        \n",
    "        # Monthly seasonality\n",
    "        month_multipliers = [0.8, 0.8, 0.9, 1.0, 1.1, 1.2, 1.2, 1.1, 1.0, 1.1, 1.3, 1.4]\n",
    "        base_demand *= df['date'].dt.month.map(lambda x: month_multipliers[x-1])\n",
    "        \n",
    "        # Add random variation\n",
    "        base_demand *= np.random.uniform(0.7, 1.3, len(df))\n",
    "        \n",
    "        return np.maximum(0.5, base_demand)\n",
    "\n",
    "    def _add_vectorized_data_issues(self, df):\n",
    "        \"\"\"Add data quality issues using vectorized operations\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Missing values (15% chance)\n",
    "        missing_mask = np.random.random(len(df)) < 0.15\n",
    "        price_missing = missing_mask & (np.random.random(len(df)) < 0.5)\n",
    "        revenue_missing = missing_mask & ~price_missing\n",
    "        \n",
    "        df.loc[price_missing, 'unit_price'] = np.nan\n",
    "        df.loc[revenue_missing, 'total_revenue'] = np.nan\n",
    "        \n",
    "        # Duplicate transaction IDs (1% chance)\n",
    "        duplicate_mask = np.random.random(len(df)) < 0.01\n",
    "        df.loc[duplicate_mask, 'transaction_id'] = 'TXN12345'\n",
    "        \n",
    "        # Outliers (2% chance)\n",
    "        outlier_mask = np.random.random(len(df)) < 0.02\n",
    "        df.loc[outlier_mask, 'sales_quantity'] *= np.random.randint(10, 100, outlier_mask.sum())\n",
    "        \n",
    "        # Negative values (0.5% chance)\n",
    "        negative_mask = np.random.random(len(df)) < 0.005\n",
    "        df.loc[negative_mask, 'sales_quantity'] *= -1\n",
    "        \n",
    "        # Wrong store IDs (1% chance)\n",
    "        wrong_store_mask = np.random.random(len(df)) < 0.01\n",
    "        df.loc[wrong_store_mask, 'store_id'] = 'ST999'\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def generate_inventory_data(self, sample_rate=0.4):\n",
    "        \"\"\"Generate inventory data - optimized\"\"\"\n",
    "        print(\"üì¶ Generating inventory data...\")\n",
    "        \n",
    "        inventory_data = []\n",
    "        date_range = pd.date_range('2022-01-01', '2024-01-01', freq='W')  # Weekly snapshots\n",
    "        \n",
    "        for date in date_range:\n",
    "            for _, store in self.stores.iterrows():\n",
    "                for _, product in self.products.iterrows():\n",
    "                    if random.random() < sample_rate:\n",
    "                        avg_weekly_sales = np.random.uniform(10, 200)\n",
    "                        current_stock = max(0, int(np.random.uniform(0, avg_weekly_sales * 4)))\n",
    "                        \n",
    "                        record = {\n",
    "                            'store_id': store['store_id'],\n",
    "                            'product_id': product['product_id'],\n",
    "                            'snapshot_date': date,\n",
    "                            'current_stock': current_stock,\n",
    "                            'reorder_point': int(avg_weekly_sales * 1.5),\n",
    "                            'max_stock_level': int(avg_weekly_sales * 6),\n",
    "                            'supplier_lead_time': np.random.choice([1, 3, 5, 7, 14]),\n",
    "                            'last_reorder_date': date - timedelta(days=random.randint(1, 30))\n",
    "                        }\n",
    "                        \n",
    "                        # Add data issues\n",
    "                        if random.random() < 0.1:\n",
    "                            record['current_stock'] = None\n",
    "                        if random.random() < 0.05:\n",
    "                            record['reorder_point'] = -10\n",
    "                            \n",
    "                        inventory_data.append(record)\n",
    "        \n",
    "        print(f\"‚úÖ Generated {len(inventory_data)} inventory records\")\n",
    "        return pd.DataFrame(inventory_data)\n",
    "\n",
    "    def generate_external_data(self):\n",
    "        \"\"\"Generate external factors data\"\"\"\n",
    "        print(\"üå°Ô∏è Generating external factors...\")\n",
    "        \n",
    "        external_data = []\n",
    "        date_range = pd.date_range('2022-01-01', '2024-01-01', freq='D')\n",
    "        cities = self.stores['city'].unique()\n",
    "        \n",
    "        for date in date_range:\n",
    "            for city in cities:\n",
    "                record = {\n",
    "                    'date': date,\n",
    "                    'city': city,\n",
    "                    'temperature': round(np.random.normal(65, 20), 1),\n",
    "                    'precipitation': max(0, round(np.random.exponential(0.1), 2)),\n",
    "                    'is_weekend': date.weekday() >= 5,\n",
    "                    'day_of_week': date.strftime('%A'),\n",
    "                    'month': date.month,\n",
    "                    'quarter': (date.month - 1) // 3 + 1,\n",
    "                    'competitor_promotion': random.random() < 0.1,\n",
    "                    'local_event': random.random() < 0.05\n",
    "                }\n",
    "                \n",
    "                # Data quality issues\n",
    "                if random.random() < 0.08:\n",
    "                    record['temperature'] = None\n",
    "                if random.random() < 0.03:\n",
    "                    record['day_of_week'] = date.strftime('%a').upper()\n",
    "                    \n",
    "                external_data.append(record)\n",
    "        \n",
    "        print(f\"‚úÖ Generated {len(external_data)} external factor records\")\n",
    "        return pd.DataFrame(external_data)\n",
    "\n",
    "# Main generation function\n",
    "def generate_all_data_fast():\n",
    "    \"\"\"Optimized main function to generate all synthetic datasets\"\"\"\n",
    "    print(\"üè≠ Generating synthetic data with optimized approach...\")\n",
    "    \n",
    "    generator = OptimizedInventoryDataGenerator()\n",
    "    \n",
    "    # Generate datasets with progress tracking\n",
    "    print(\"\\nüìä Generating sales transactions...\")\n",
    "    sales_df = generator.generate_sales_data_optimized(sample_rate=0.3)  # Reduced sample rate for speed\n",
    "    \n",
    "    print(\"\\nüì¶ Generating inventory snapshots...\")\n",
    "    inventory_df = generator.generate_inventory_data(sample_rate=0.4)\n",
    "    \n",
    "    print(\"\\nüå°Ô∏è Generating external factors...\")\n",
    "    external_df = generator.generate_external_data()\n",
    "    \n",
    "    # Create summary\n",
    "    summary = {\n",
    "        'generation_date': datetime.now().isoformat(),\n",
    "        'datasets': {\n",
    "            'sales_transactions': {\n",
    "                'rows': len(sales_df),\n",
    "                'date_range': f\"{sales_df['date'].min()} to {sales_df['date'].max()}\",\n",
    "                'missing_values': sales_df.isnull().sum().sum(),\n",
    "                'stores': sales_df['store_id'].nunique(),\n",
    "                'products': sales_df['product_id'].nunique()\n",
    "            },\n",
    "            'inventory_levels': {\n",
    "                'rows': len(inventory_df),\n",
    "                'missing_values': inventory_df.isnull().sum().sum()\n",
    "            },\n",
    "            'external_factors': {\n",
    "                'rows': len(external_df),\n",
    "                'cities': external_df['city'].nunique(),\n",
    "                'missing_values': external_df.isnull().sum().sum()\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"\\n‚úÖ Data generation complete!\")\n",
    "    print(f\"üìà Sales records: {len(sales_df):,}\")\n",
    "    print(f\"üì¶ Inventory snapshots: {len(inventory_df):,}\")\n",
    "    print(f\"üå°Ô∏è External factor records: {len(external_df):,}\")\n",
    "    print(f\"üö® Total missing values: {sales_df.isnull().sum().sum() + inventory_df.isnull().sum().sum() + external_df.isnull().sum().sum()}\")\n",
    "    \n",
    "    return sales_df, inventory_df, external_df, generator.stores, generator.products, summary\n",
    "\n",
    "# Test the optimized version\n",
    "if __name__ == \"__main__\":\n",
    "    sales_df, inventory_df, external_df, stores_df, products_df, summary = generate_all_data_fast()\n",
    "    \n",
    "    # Display sample data\n",
    "    print(\"\\nüîç Sample Sales Data:\")\n",
    "    print(sales_df.head())\n",
    "    \n",
    "    print(\"\\nüîç Data Quality Issues:\")\n",
    "    print(f\"Missing values: {sales_df.isnull().sum().sum()}\")\n",
    "    print(f\"Negative quantities: {(sales_df['sales_quantity'] < 0).sum()}\")\n",
    "    print(f\"Duplicate transaction IDs: {sales_df['transaction_id'].duplicated().sum()}\")\n",
    "    print(f\"Wrong store IDs: {(sales_df['store_id'] == 'ST999').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b537536-8720-410f-b117-ad650b97720d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting fast data generation...\n",
      "üè≠ Generating synthetic data with optimized approach...\n",
      "‚úÖ Initialized: 5 stores, 40 products\n",
      "\n",
      "üìä Generating sales transactions...\n",
      "üöÄ Generating sales data with optimized approach...\n",
      "üìä Processing 43777 combinations...\n",
      "üî¢ Calculating demand patterns...\n",
      "üîß Adding realistic data quality issues...\n",
      "‚úÖ Generated 40470 sales records\n",
      "\n",
      "üì¶ Generating inventory snapshots...\n",
      "üì¶ Generating inventory data...\n",
      "‚úÖ Generated 8343 inventory records\n",
      "\n",
      "üå°Ô∏è Generating external factors...\n",
      "üå°Ô∏è Generating external factors...\n",
      "‚úÖ Generated 3655 external factor records\n",
      "\n",
      "‚úÖ Data generation complete!\n",
      "üìà Sales records: 40,470\n",
      "üì¶ Inventory snapshots: 8,343\n",
      "üå°Ô∏è External factor records: 3,655\n",
      "üö® Total missing values: 7138\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Generate the data\n",
    "print(\"üöÄ Starting fast data generation...\")\n",
    "sales_df, inventory_df, external_df, stores_df, products_df, summary = generate_all_data_fast()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb3efd8-46ae-4cee-b376-82f2342c4283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA OVERVIEW ===\n",
      "Sales data shape: (40470, 7)\n",
      "Inventory data shape: (8343, 8)\n",
      "External data shape: (3655, 10)\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Quick data overview\n",
    "print(\"=== DATA OVERVIEW ===\")\n",
    "print(f\"Sales data shape: {sales_df.shape}\")\n",
    "print(f\"Inventory data shape: {inventory_df.shape}\")\n",
    "print(f\"External data shape: {external_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba39bf7-0643-4dcc-a7c8-a9168054b7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAMPLE DATA ===\n",
      "Sales data sample:\n",
      "  transaction_id store_id product_id       date  sales_quantity  unit_price  \\\n",
      "0       TXN72449    ST001       P001 2022-01-01               4      180.76   \n",
      "1       TXN25921    ST001       P003 2022-01-01              16      340.00   \n",
      "2       TXN12345    ST001       P004 2022-01-01              14      239.67   \n",
      "3       TXN61515    ST001       P006 2022-01-01               9      309.04   \n",
      "4       TXN98706    ST001       P009 2022-01-01              12      131.46   \n",
      "\n",
      "   total_revenue  \n",
      "0         723.04  \n",
      "1        5440.00  \n",
      "2        3355.38  \n",
      "3        2781.36  \n",
      "4        1577.52  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== SAMPLE DATA ===\")\n",
    "print(\"Sales data sample:\")\n",
    "print(sales_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "578afb7d-fa5f-4e70-ac4d-d798a96b47be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA QUALITY ISSUES ===\n",
      "Sales data missing values by column:\n",
      "transaction_id       0\n",
      "store_id             0\n",
      "product_id           0\n",
      "date                 0\n",
      "sales_quantity       0\n",
      "unit_price        2980\n",
      "total_revenue     3013\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Check data quality issues\n",
    "print(\"=== DATA QUALITY ISSUES ===\")\n",
    "print(\"Sales data missing values by column:\")\n",
    "print(sales_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6800407f-2a26-4906-9654-e9f13ba45957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Negative sales quantities: 185\n",
      "Duplicate transaction IDs: 8173\n",
      "Wrong store IDs (ST999): 388\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nNegative sales quantities: {(sales_df['sales_quantity'] < 0).sum()}\")\n",
    "print(f\"Duplicate transaction IDs: {sales_df['transaction_id'].duplicated().sum()}\")\n",
    "print(f\"Wrong store IDs (ST999): {(sales_df['store_id'] == 'ST999').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "406f537a-e080-41c7-a767-931dcef00739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data saved to CSV files!\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Save data (optional)\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "sales_df.to_csv('data/sales_transactions.csv', index=False)\n",
    "inventory_df.to_csv('data/inventory_levels.csv', index=False)\n",
    "external_df.to_csv('data/external_factors.csv', index=False)\n",
    "stores_df.to_csv('data/stores.csv', index=False)\n",
    "products_df.to_csv('data/products.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Data saved to CSV files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a9f5c4-a3e6-48bf-82ba-a46c808b1e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
